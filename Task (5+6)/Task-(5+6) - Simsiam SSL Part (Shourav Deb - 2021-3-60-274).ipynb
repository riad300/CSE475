{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## TASK 4 (SimSiam SSL)  (FT)\n",
    "### By: Shourav Chandra Deb [2021-3-60-274]\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 1 - Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:57:35.011783Z",
     "iopub.status.busy": "2025-11-27T16:57:35.011206Z",
     "iopub.status.idle": "2025-11-27T16:57:41.554295Z",
     "shell.execute_reply": "2025-11-27T16:57:41.553592Z",
     "shell.execute_reply.started": "2025-11-27T16:57:35.011753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG\n",
      "DATA_DIR: /kaggle/input/betel-leaf/Betel Leaf Dataset A Primary Dataset From Field And Controlled Environment/Betel Leaf Dataset\n",
      "RESOLUTION: 224\n",
      "PRETRAIN_EPOCHS: 100\n",
      "BATCH_SIZE: 64\n",
      "BACKBONE: resnet18\n",
      "OUT_DIR: /kaggle/working/simsiam_task4\n"
     ]
    }
   ],
   "source": [
    "import os, random, json, time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/betel-leaf\"   \n",
    "RESOLUTION = 224\n",
    "PRETRAIN_EPOCHS = 100\n",
    "\n",
    "LINEAR_EPOCHS = 50\n",
    "FINETUNE_EPOCHS = 50\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BACKBONE = \"resnet18\"\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "OUT_DIR = \"/kaggle/working/simsiam_task4\"\n",
    "\n",
    "assert os.path.exists(DATA_DIR), f\"DATA_DIR not found: {DATA_DIR}\"\n",
    "assert PRETRAIN_EPOCHS >= 100, \"PRETRAIN_EPOCHS must be >= 100\"\n",
    "assert isinstance(RESOLUTION, int) and RESOLUTION >= 64, \"RESOLUTION must be integer >=64\"\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"CONFIG\")\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"RESOLUTION:\", RESOLUTION)\n",
    "print(\"PRETRAIN_EPOCHS:\", PRETRAIN_EPOCHS)\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "print(\"BACKBONE:\", BACKBONE)\n",
    "print(\"OUT_DIR:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 2 - Imports & Basic Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:58:43.704381Z",
     "iopub.status.busy": "2025-11-27T16:58:43.703290Z",
     "iopub.status.idle": "2025-11-27T16:58:43.719023Z",
     "shell.execute_reply": "2025-11-27T16:58:43.718132Z",
     "shell.execute_reply.started": "2025-11-27T16:58:43.704350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "PyTorch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device count: 2\n",
      "CUDA current device: 0\n",
      "CUDA device name: Tesla T4\n",
      "matplotlib: 3.7.2\n",
      "seaborn: 0.12.2\n",
      "scikit-learn: 1.2.2\n",
      "umap-learn: 0.5.9.post2\n",
      "TensorFlow: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")\n",
    "os.environ.setdefault(\"XLA_FLAGS\", \"--xla_gpu_cuda_data_dir=/usr/local/cuda  --xla_force_host_platform_device_count=1\")\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from typing import Optional\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception as e:\n",
    "    sns = None\n",
    "    print(\"Warning: seaborn import failed — continuing without it:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    import torchvision\n",
    "    from torchvision import transforms, models\n",
    "except Exception as e:\n",
    "    torch = None\n",
    "    nn = None\n",
    "    optim = None\n",
    "    DataLoader = None\n",
    "    Dataset = None\n",
    "    torchvision = None\n",
    "    transforms = None\n",
    "    models = None\n",
    "    print(\"Warning: PyTorch imports failed or CUDA unavailable:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except Exception as e:\n",
    "    print(\"Warning: scikit-learn import failed:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "except Exception as e:\n",
    "    umap = None\n",
    "    print(\"Info: umap not available:\", e)\n",
    "\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.metrics import silhouette_score\n",
    "except Exception as e:\n",
    "    print(\"Warning importing TSNE / silhouette_score:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    import joblib\n",
    "    import pickle\n",
    "except Exception as e:\n",
    "    print(\"Warning: joblib/pickle import issue:\", e)\n",
    "\n",
    "\n",
    "def env_diagnostics(show_packages: Optional[list] = None):\n",
    "    \"\"\"Print device + common package versions to help debug environment mismatches.\"\"\"\n",
    "    print(\"Python:\", sys.version.splitlines()[0])\n",
    "    \n",
    "    if torch is not None:\n",
    "        try:\n",
    "            print(\"PyTorch:\", torch.__version__)\n",
    "            print(\"CUDA available:\", torch.cuda.is_available())\n",
    "            if torch.cuda.is_available():\n",
    "                print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "                print(\"CUDA current device:\", torch.cuda.current_device())\n",
    "                print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "        except Exception as e:\n",
    "            print(\"PyTorch diagnostic error:\", e)\n",
    "    else:\n",
    "        print(\"PyTorch: not available\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        import matplotlib\n",
    "        print(\"matplotlib:\", matplotlib.__version__)\n",
    "    except Exception:\n",
    "        print(\"matplotlib: not available\")\n",
    "\n",
    "    if sns is not None:\n",
    "        try:\n",
    "            print(\"seaborn:\", sns.__version__)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    try:\n",
    "        import sklearn\n",
    "        print(\"scikit-learn:\", sklearn.__version__)\n",
    "    except Exception:\n",
    "        print(\"scikit-learn: not available\")\n",
    "\n",
    "    \n",
    "    if umap is not None:\n",
    "        try:\n",
    "            print(\"umap-learn:\", umap.__version__)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        import importlib\n",
    "        if importlib.util.find_spec(\"tensorflow\") is not None:\n",
    "            import tensorflow as tf\n",
    "            print(\"TensorFlow:\", tf.__version__)\n",
    "           \n",
    "        else:\n",
    "            print(\"TensorFlow: not installed (or not found in this env)\")\n",
    "    except Exception as e:\n",
    "       \n",
    "        print(\"TensorFlow import safe-check raised an exception (not fatal):\", e)\n",
    "\n",
    "\n",
    "if torch is not None:\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "env_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 3 - Build file manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:59:12.787324Z",
     "iopub.status.busy": "2025-11-27T16:59:12.786661Z",
     "iopub.status.idle": "2025-11-27T16:59:12.953319Z",
     "shell.execute_reply": "2025-11-27T16:59:12.952481Z",
     "shell.execute_reply.started": "2025-11-27T16:59:12.787296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected top-level source folders: ['On Field', 'Controlled Environment']\n",
      "\n",
      "Source 'On Field' subfolders: ['Diseased Leaf', 'Healthy Leaf', 'Dried Leaf']\n",
      "\n",
      "Source 'Controlled Environment' subfolders: ['Diseased', 'Dried', 'Healthy']\n",
      "\n",
      "Total images found: 1800\n",
      "Per-subfolder counts:\n",
      "  Diseased Leaf: 289\n",
      "  Dried Leaf: 282\n",
      "  Healthy Leaf: 336\n",
      "  Diseased: 220\n",
      "  Dried: 340\n",
      "  Healthy: 333\n",
      "\n",
      "Manifest saved to /kaggle/working/simsiam_task4/manifest.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "root = Path(\"/kaggle/input/betel-leaf\")\n",
    "assert root.exists(), f\"Dataset root missing: {root}\"\n",
    "\n",
    "expected_classes = [\"Diseased\", \"Dried\", \"Healthy\"]\n",
    "sources = [p.name for p in root.iterdir() if p.is_dir()]\n",
    "print(\"Detected top-level source folders:\", sources)\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "found_map = {}\n",
    "\n",
    "def normalize(name: str):\n",
    "    \"\"\"Utility to normalize folder names for matching.\"\"\"\n",
    "    return name.lower().replace(\" \", \"\").replace(\"_\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "for src in sources:\n",
    "    src_dir = root / src\n",
    "    subdirs = [d.name for d in src_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"\\nSource '{src}' subfolders:\", subdirs)\n",
    "\n",
    "    for cls in expected_classes:\n",
    "        cls_norm = normalize(cls)\n",
    "        matched = None\n",
    "\n",
    "        for s in subdirs:\n",
    "            if cls_norm in normalize(s):\n",
    "                matched = s\n",
    "                break\n",
    "\n",
    "        if matched is None:\n",
    "            print(f\"WARNING: class '{cls}' not found under '{src}'\")\n",
    "            continue\n",
    "\n",
    "        found_map.setdefault(src, {})[cls] = matched\n",
    "        cls_dir = src_dir / matched\n",
    "\n",
    "        for p in cls_dir.glob(\"*\"):\n",
    "            if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                filepaths.append(str(p))\n",
    "                labels.append(expected_classes.index(cls))\n",
    "\n",
    "print(\"\\nTotal images found:\", len(filepaths))\n",
    "from collections import Counter\n",
    "ctr = Counter([Path(p).parent.name for p in filepaths])\n",
    "print(\"Per-subfolder counts:\")\n",
    "for k, v in ctr.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "manifest = {\n",
    "    \"classes\": expected_classes,\n",
    "    \"sources_detected\": sources,\n",
    "    \"found_map\": found_map,\n",
    "    \"files\": filepaths,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "os.makedirs(\"/kaggle/working/simsiam_task4\", exist_ok=True)\n",
    "with open(\"/kaggle/working/simsiam_task4/manifest.json\", \"w\") as f:\n",
    "    json.dump(manifest, f)\n",
    "print(\"\\nManifest saved to /kaggle/working/simsiam_task4/manifest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 4 - Transforms (SimSiam two-view + eval transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:59:20.054515Z",
     "iopub.status.busy": "2025-11-27T16:59:20.054247Z",
     "iopub.status.idle": "2025-11-27T16:59:20.063023Z",
     "shell.execute_reply": "2025-11-27T16:59:20.062412Z",
     "shell.execute_reply.started": "2025-11-27T16:59:20.054496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "simsiam_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(RESOLUTION, scale=(0.2, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.02),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(int(RESOLUTION * 1.1)),\n",
    "    transforms.CenterCrop(RESOLUTION),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def aug_probe_image(path, n=6):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        timg = simsiam_transform(img)\n",
    "        t = timg.numpy().transpose(1,2,0)\n",
    "        t = t * np.array([0.229,0.224,0.225]) + np.array([0.485,0.456,0.406])\n",
    "        t = np.clip(t, 0, 1)\n",
    "        outs.append((t*255).astype(np.uint8))\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 5 - Dataset wrappers: TwoViewDataset + ManifestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:59:34.254711Z",
     "iopub.status.busy": "2025-11-27T16:59:34.254005Z",
     "iopub.status.idle": "2025-11-27T16:59:34.261835Z",
     "shell.execute_reply": "2025-11-27T16:59:34.261042Z",
     "shell.execute_reply.started": "2025-11-27T16:59:34.254680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TwoViewDataset(Dataset):\n",
    "    \"\"\"Returns two different augmented views of the same image (for SimSiam).\"\"\"\n",
    "    def __init__(self, paths, labels, transform):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        lbl = self.labels[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        x1 = self.transform(img)\n",
    "        x2 = self.transform(img)\n",
    "        return x1, x2, lbl, p\n",
    "\n",
    "class ManifestDataset(Dataset):\n",
    "    \"\"\"Deterministic dataset for feature extraction and downstream training.\"\"\"\n",
    "    def __init__(self, paths, labels, transform):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        lbl = self.labels[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, lbl, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 6 - Create train/val/test splits and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:59:45.347387Z",
     "iopub.status.busy": "2025-11-27T16:59:45.347054Z",
     "iopub.status.idle": "2025-11-27T16:59:45.375325Z",
     "shell.execute_reply": "2025-11-27T16:59:45.374603Z",
     "shell.execute_reply.started": "2025-11-27T16:59:45.347361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1296 Val: 144 Test: 360\n",
      "Split manifest saved to /kaggle/working/simsiam_task4/split_manifest.json\n"
     ]
    }
   ],
   "source": [
    "paths = manifest[\"files\"]\n",
    "labels = manifest[\"labels\"]\n",
    "classes = manifest[\"classes\"]\n",
    "\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    paths, labels, test_size=0.20, stratify=labels, random_state=SEED)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_paths, train_labels, test_size=0.10, stratify=train_labels, random_state=SEED)\n",
    "\n",
    "print(\"Train:\", len(train_paths), \"Val:\", len(val_paths), \"Test:\", len(test_paths))\n",
    "\n",
    "split_manifest = {\n",
    "    \"classes\": classes,\n",
    "    \"train\": train_paths, \"train_labels\": train_labels,\n",
    "    \"val\": val_paths, \"val_labels\": val_labels,\n",
    "    \"test\": test_paths, \"test_labels\": test_labels\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"split_manifest.json\"), \"w\") as f:\n",
    "    json.dump(split_manifest, f)\n",
    "print(\"Split manifest saved to\", os.path.join(OUT_DIR, \"split_manifest.json\"))\n",
    "\n",
    "train_dataset = TwoViewDataset(train_paths, train_labels, simsiam_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, drop_last=True)\n",
    "\n",
    "val_dataset = ManifestDataset(val_paths, val_labels, eval_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_dataset = ManifestDataset(test_paths, test_labels, eval_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 7 - SimSiam model definition (encoder, projector, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:59:56.068031Z",
     "iopub.status.busy": "2025-11-27T16:59:56.067150Z",
     "iopub.status.idle": "2025-11-27T16:59:56.077102Z",
     "shell.execute_reply": "2025-11-27T16:59:56.076106Z",
     "shell.execute_reply.started": "2025-11-27T16:59:56.067999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, backbone=\"resnet18\", pretrained=False, proj_hidden=2048, pred_hidden=512, out_dim=512):\n",
    "        super().__init__()\n",
    "        if backbone == \"resnet18\":\n",
    "            base = models.resnet18(pretrained=pretrained)\n",
    "            feat_dim = 512\n",
    "        elif backbone == \"resnet50\":\n",
    "            base = models.resnet50(pretrained=pretrained)\n",
    "            feat_dim = 2048\n",
    "        else:\n",
    "            raise ValueError(\"backbone must be resnet18 or resnet50\")\n",
    "        modules = list(base.children())[:-1]\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(feat_dim, proj_hidden),\n",
    "            nn.BatchNorm1d(proj_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(proj_hidden, proj_hidden),\n",
    "            nn.BatchNorm1d(proj_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(proj_hidden, out_dim)\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(out_dim, pred_hidden),\n",
    "            nn.BatchNorm1d(pred_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(pred_hidden, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward_backbone(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        return h\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        h1 = self.forward_backbone(x1)\n",
    "        h2 = self.forward_backbone(x2)\n",
    "        z1 = self.projector(h1)\n",
    "        z2 = self.projector(h2)\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1.detach(), z2.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 8 - Loss function (negative cosine similarity) & utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T17:00:09.038653Z",
     "iopub.status.busy": "2025-11-27T17:00:09.038312Z",
     "iopub.status.idle": "2025-11-27T17:00:09.045559Z",
     "shell.execute_reply": "2025-11-27T17:00:09.044485Z",
     "shell.execute_reply.started": "2025-11-27T17:00:09.038628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def negative_cosine_similarity(p, z):\n",
    "    p = nn.functional.normalize(p, dim=1)\n",
    "    z = nn.functional.normalize(z, dim=1)\n",
    "    return - (p * z).sum(dim=1).mean()\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "    print(\"Saved checkpoint:\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 9 - Pretraining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T19:20:26.189444Z",
     "iopub.status.busy": "2025-11-23T19:20:26.188907Z",
     "iopub.status.idle": "2025-11-24T05:49:19.686304Z",
     "shell.execute_reply": "2025-11-24T05:49:19.685492Z",
     "shell.execute_reply.started": "2025-11-23T19:20:26.189421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pretraining for 100 epochs (from epoch 0 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/100: 100%|██████████| 20/20 [06:57<00:00, 20.89s/it, loss=-0.1287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Avg loss: -0.1287\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/100: 100%|██████████| 20/20 [06:21<00:00, 19.07s/it, loss=-0.4303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished. Avg loss: -0.4303\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/100: 100%|██████████| 20/20 [06:14<00:00, 18.73s/it, loss=-0.5787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished. Avg loss: -0.5787\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/100: 100%|██████████| 20/20 [06:10<00:00, 18.51s/it, loss=-0.6860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished. Avg loss: -0.6860\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/100: 100%|██████████| 20/20 [06:19<00:00, 18.96s/it, loss=-0.7681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished. Avg loss: -0.7681\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 6/100: 100%|██████████| 20/20 [06:10<00:00, 18.54s/it, loss=-0.8111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 finished. Avg loss: -0.8111\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 7/100: 100%|██████████| 20/20 [06:13<00:00, 18.67s/it, loss=-0.8327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 finished. Avg loss: -0.8327\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 8/100: 100%|██████████| 20/20 [06:14<00:00, 18.72s/it, loss=-0.8515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 finished. Avg loss: -0.8515\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 9/100: 100%|██████████| 20/20 [06:17<00:00, 18.88s/it, loss=-0.8444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 finished. Avg loss: -0.8444\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 10/100: 100%|██████████| 20/20 [06:17<00:00, 18.89s/it, loss=-0.8696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 finished. Avg loss: -0.8696\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 11/100: 100%|██████████| 20/20 [06:19<00:00, 18.98s/it, loss=-0.8581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 finished. Avg loss: -0.8581\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 12/100: 100%|██████████| 20/20 [06:14<00:00, 18.72s/it, loss=-0.8753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 finished. Avg loss: -0.8753\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 13/100: 100%|██████████| 20/20 [06:06<00:00, 18.35s/it, loss=-0.8759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 finished. Avg loss: -0.8759\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 14/100: 100%|██████████| 20/20 [06:13<00:00, 18.68s/it, loss=-0.8736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 finished. Avg loss: -0.8736\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 15/100: 100%|██████████| 20/20 [06:13<00:00, 18.65s/it, loss=-0.8942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 finished. Avg loss: -0.8942\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 16/100: 100%|██████████| 20/20 [06:19<00:00, 18.98s/it, loss=-0.8858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 finished. Avg loss: -0.8858\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 17/100: 100%|██████████| 20/20 [06:13<00:00, 18.67s/it, loss=-0.8934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 finished. Avg loss: -0.8934\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 18/100: 100%|██████████| 20/20 [05:59<00:00, 18.00s/it, loss=-0.8937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 finished. Avg loss: -0.8937\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 19/100: 100%|██████████| 20/20 [06:17<00:00, 18.90s/it, loss=-0.8942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 finished. Avg loss: -0.8942\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 20/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.9003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 finished. Avg loss: -0.9003\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 21/100: 100%|██████████| 20/20 [06:11<00:00, 18.59s/it, loss=-0.8986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 finished. Avg loss: -0.8986\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 22/100: 100%|██████████| 20/20 [06:11<00:00, 18.58s/it, loss=-0.8984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 finished. Avg loss: -0.8984\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 23/100: 100%|██████████| 20/20 [06:20<00:00, 19.04s/it, loss=-0.8972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 finished. Avg loss: -0.8972\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 24/100: 100%|██████████| 20/20 [06:18<00:00, 18.91s/it, loss=-0.8948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 finished. Avg loss: -0.8948\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 25/100: 100%|██████████| 20/20 [06:03<00:00, 18.16s/it, loss=-0.8922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 finished. Avg loss: -0.8922\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 26/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.8974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 finished. Avg loss: -0.8974\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 27/100: 100%|██████████| 20/20 [06:16<00:00, 18.80s/it, loss=-0.8999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 finished. Avg loss: -0.8999\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 28/100: 100%|██████████| 20/20 [06:10<00:00, 18.54s/it, loss=-0.9013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 finished. Avg loss: -0.9013\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 29/100: 100%|██████████| 20/20 [06:20<00:00, 19.02s/it, loss=-0.9023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 finished. Avg loss: -0.9023\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 30/100: 100%|██████████| 20/20 [06:21<00:00, 19.08s/it, loss=-0.9070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 finished. Avg loss: -0.9070\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 31/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 finished. Avg loss: -0.9009\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 32/100: 100%|██████████| 20/20 [06:28<00:00, 19.40s/it, loss=-0.9014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 finished. Avg loss: -0.9014\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 33/100: 100%|██████████| 20/20 [06:12<00:00, 18.64s/it, loss=-0.8989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 finished. Avg loss: -0.8989\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 34/100: 100%|██████████| 20/20 [06:18<00:00, 18.91s/it, loss=-0.9083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 finished. Avg loss: -0.9083\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 35/100: 100%|██████████| 20/20 [06:20<00:00, 19.03s/it, loss=-0.9056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 finished. Avg loss: -0.9056\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 36/100: 100%|██████████| 20/20 [06:13<00:00, 18.67s/it, loss=-0.9021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 finished. Avg loss: -0.9021\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 37/100: 100%|██████████| 20/20 [06:19<00:00, 18.96s/it, loss=-0.9027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 finished. Avg loss: -0.9027\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 38/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 finished. Avg loss: -0.9024\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 39/100: 100%|██████████| 20/20 [06:17<00:00, 18.87s/it, loss=-0.9041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 finished. Avg loss: -0.9041\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 40/100: 100%|██████████| 20/20 [06:15<00:00, 18.77s/it, loss=-0.9015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 finished. Avg loss: -0.9015\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 41/100: 100%|██████████| 20/20 [06:12<00:00, 18.61s/it, loss=-0.8954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 finished. Avg loss: -0.8954\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 42/100: 100%|██████████| 20/20 [06:16<00:00, 18.84s/it, loss=-0.9000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 finished. Avg loss: -0.9000\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 43/100: 100%|██████████| 20/20 [06:20<00:00, 19.05s/it, loss=-0.9058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 finished. Avg loss: -0.9058\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 44/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 finished. Avg loss: -0.9043\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 45/100: 100%|██████████| 20/20 [06:25<00:00, 19.29s/it, loss=-0.9010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 finished. Avg loss: -0.9010\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 46/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 finished. Avg loss: -0.9076\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 47/100: 100%|██████████| 20/20 [06:16<00:00, 18.82s/it, loss=-0.9098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 finished. Avg loss: -0.9098\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 48/100: 100%|██████████| 20/20 [06:14<00:00, 18.73s/it, loss=-0.9045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 finished. Avg loss: -0.9045\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 49/100: 100%|██████████| 20/20 [06:23<00:00, 19.17s/it, loss=-0.9105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 finished. Avg loss: -0.9105\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 50/100: 100%|██████████| 20/20 [06:11<00:00, 18.60s/it, loss=-0.9072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 finished. Avg loss: -0.9072\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 51/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 finished. Avg loss: -0.9112\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 52/100: 100%|██████████| 20/20 [06:18<00:00, 18.93s/it, loss=-0.9114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 finished. Avg loss: -0.9114\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 53/100: 100%|██████████| 20/20 [06:14<00:00, 18.74s/it, loss=-0.9047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 finished. Avg loss: -0.9047\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 54/100: 100%|██████████| 20/20 [06:29<00:00, 19.47s/it, loss=-0.8987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 finished. Avg loss: -0.8987\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 55/100: 100%|██████████| 20/20 [06:21<00:00, 19.05s/it, loss=-0.9183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 finished. Avg loss: -0.9183\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 56/100: 100%|██████████| 20/20 [06:15<00:00, 18.76s/it, loss=-0.9190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 finished. Avg loss: -0.9190\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 57/100: 100%|██████████| 20/20 [06:17<00:00, 18.88s/it, loss=-0.9139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 finished. Avg loss: -0.9139\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 58/100: 100%|██████████| 20/20 [06:24<00:00, 19.23s/it, loss=-0.9146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 finished. Avg loss: -0.9146\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 59/100: 100%|██████████| 20/20 [06:18<00:00, 18.92s/it, loss=-0.9131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 finished. Avg loss: -0.9131\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 60/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 finished. Avg loss: -0.9122\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 61/100: 100%|██████████| 20/20 [06:19<00:00, 18.98s/it, loss=-0.9176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 finished. Avg loss: -0.9176\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 62/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.9130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 finished. Avg loss: -0.9130\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 63/100: 100%|██████████| 20/20 [06:18<00:00, 18.93s/it, loss=-0.9147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 finished. Avg loss: -0.9147\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 64/100: 100%|██████████| 20/20 [06:21<00:00, 19.07s/it, loss=-0.9130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 finished. Avg loss: -0.9130\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 65/100: 100%|██████████| 20/20 [06:19<00:00, 18.99s/it, loss=-0.9130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 finished. Avg loss: -0.9130\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 66/100: 100%|██████████| 20/20 [06:20<00:00, 19.02s/it, loss=-0.9187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 finished. Avg loss: -0.9187\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 67/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.9150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 finished. Avg loss: -0.9150\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 68/100: 100%|██████████| 20/20 [06:05<00:00, 18.28s/it, loss=-0.9201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 finished. Avg loss: -0.9201\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 69/100: 100%|██████████| 20/20 [06:22<00:00, 19.14s/it, loss=-0.9135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 finished. Avg loss: -0.9135\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 70/100: 100%|██████████| 20/20 [06:23<00:00, 19.18s/it, loss=-0.9123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 finished. Avg loss: -0.9123\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 71/100: 100%|██████████| 20/20 [06:22<00:00, 19.10s/it, loss=-0.9177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 finished. Avg loss: -0.9177\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 72/100: 100%|██████████| 20/20 [06:20<00:00, 19.03s/it, loss=-0.9154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 finished. Avg loss: -0.9154\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 73/100: 100%|██████████| 20/20 [06:24<00:00, 19.22s/it, loss=-0.9192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 finished. Avg loss: -0.9192\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 74/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 finished. Avg loss: -0.9154\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 75/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 finished. Avg loss: -0.9158\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 76/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 finished. Avg loss: -0.9128\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 77/100: 100%|██████████| 20/20 [06:13<00:00, 18.69s/it, loss=-0.9191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 finished. Avg loss: -0.9191\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 78/100: 100%|██████████| 20/20 [06:13<00:00, 18.65s/it, loss=-0.9230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 finished. Avg loss: -0.9230\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 79/100: 100%|██████████| 20/20 [06:17<00:00, 18.88s/it, loss=-0.9172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 finished. Avg loss: -0.9172\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 80/100: 100%|██████████| 20/20 [06:15<00:00, 18.77s/it, loss=-0.9178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 finished. Avg loss: -0.9178\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 81/100: 100%|██████████| 20/20 [06:12<00:00, 18.60s/it, loss=-0.9160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 finished. Avg loss: -0.9160\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 82/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 finished. Avg loss: -0.9195\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 83/100: 100%|██████████| 20/20 [06:15<00:00, 18.76s/it, loss=-0.9179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 finished. Avg loss: -0.9179\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 84/100: 100%|██████████| 20/20 [06:18<00:00, 18.92s/it, loss=-0.9208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 finished. Avg loss: -0.9208\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 85/100: 100%|██████████| 20/20 [05:50<00:00, 17.52s/it, loss=-0.9239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 finished. Avg loss: -0.9239\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 86/100: 100%|██████████| 20/20 [06:19<00:00, 18.96s/it, loss=-0.9157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 finished. Avg loss: -0.9157\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 87/100: 100%|██████████| 20/20 [06:20<00:00, 19.01s/it, loss=-0.9111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 finished. Avg loss: -0.9111\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 88/100: 100%|██████████| 20/20 [06:11<00:00, 18.60s/it, loss=-0.9194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 finished. Avg loss: -0.9194\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 89/100: 100%|██████████| 20/20 [06:14<00:00, 18.72s/it, loss=-0.9169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 finished. Avg loss: -0.9169\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 90/100: 100%|██████████| 20/20 [06:14<00:00, 18.71s/it, loss=-0.9176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 finished. Avg loss: -0.9176\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 91/100: 100%|██████████| 20/20 [06:17<00:00, 18.87s/it, loss=-0.9189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 finished. Avg loss: -0.9189\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 92/100: 100%|██████████| 20/20 [05:32<00:00, 16.64s/it, loss=-0.9194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 finished. Avg loss: -0.9194\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 93/100: 100%|██████████| 20/20 [06:16<00:00, 18.81s/it, loss=-0.9203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 finished. Avg loss: -0.9203\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 94/100: 100%|██████████| 20/20 [06:14<00:00, 18.73s/it, loss=-0.9212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 finished. Avg loss: -0.9212\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 95/100: 100%|██████████| 20/20 [06:16<00:00, 18.82s/it, loss=-0.9223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 finished. Avg loss: -0.9223\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 96/100: 100%|██████████| 20/20 [06:11<00:00, 18.57s/it, loss=-0.9198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 finished. Avg loss: -0.9198\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 97/100: 100%|██████████| 20/20 [06:14<00:00, 18.74s/it, loss=-0.9226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 finished. Avg loss: -0.9226\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 98/100: 100%|██████████| 20/20 [06:11<00:00, 18.56s/it, loss=-0.9148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 finished. Avg loss: -0.9148\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 99/100: 100%|██████████| 20/20 [06:18<00:00, 18.95s/it, loss=-0.9190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 finished. Avg loss: -0.9190\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 100/100: 100%|██████████| 20/20 [06:15<00:00, 18.76s/it, loss=-0.9217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 finished. Avg loss: -0.9217\n",
      "Saved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n",
      "Pretraining complete. Encoder saved to /kaggle/working/simsiam_task4/simsiam_encoder.pth\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.03 * (BATCH_SIZE / 256)\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "model = SimSiam(backbone=BACKBONE).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=PRETRAIN_EPOCHS)\n",
    "\n",
    "\n",
    "latest_ckpt = os.path.join(OUT_DIR, \"simsiam_latest.pth\")\n",
    "best_ckpt = os.path.join(OUT_DIR, \"simsiam_best_linearprobe.pth\")\n",
    "encoder_outpath = os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\n",
    "\n",
    "\n",
    "start_epoch = 0\n",
    "if os.path.exists(latest_ckpt):\n",
    "    ck = torch.load(latest_ckpt, map_location=DEVICE)\n",
    "    model.load_state_dict(ck[\"model_state\"])\n",
    "    optimizer.load_state_dict(ck[\"optimizer_state\"])\n",
    "    scheduler.load_state_dict(ck[\"scheduler_state\"])\n",
    "    start_epoch = ck[\"epoch\"] + 1\n",
    "    print(\"Resumed from checkpoint. Starting at epoch\", start_epoch)\n",
    "\n",
    "\n",
    "def extract_features_from_encoder(encoder, paths_list, transform, batch_size=64):\n",
    "    encoder.eval()\n",
    "    ds = ManifestDataset(paths_list, [0]*len(paths_list), transform=transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    feats = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, _, _ in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            h = encoder(imgs).view(imgs.size(0), -1).cpu().numpy()\n",
    "            feats.append(h)\n",
    "    feats = np.vstack(feats)\n",
    "    return feats\n",
    "\n",
    "\n",
    "def quick_linear_probe(encoder, train_paths, train_labels, val_paths, val_labels, transform, max_samples=500):\n",
    "\n",
    "    tpaths = train_paths[:max_samples]; tlabels = train_labels[:max_samples]\n",
    "    train_feats = extract_features_from_encoder(encoder, tpaths, transform)\n",
    "    val_feats = extract_features_from_encoder(encoder, val_paths, transform)\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(train_feats, tlabels)\n",
    "    preds = clf.predict(val_feats)\n",
    "    acc = accuracy_score(val_labels, preds)\n",
    "    return acc\n",
    "\n",
    "\n",
    "print(\"Starting pretraining for\", PRETRAIN_EPOCHS, \"epochs (from epoch\", start_epoch, \")\")\n",
    "for epoch in range(start_epoch, PRETRAIN_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    loop = tqdm(train_loader, desc=f\"Pretrain Epoch {epoch+1}/{PRETRAIN_EPOCHS}\")\n",
    "    for x1, x2, lbl, _ in loop:\n",
    "        x1 = x1.to(DEVICE); x2 = x2.to(DEVICE)\n",
    "        p1, p2, z1, z2 = model(x1, x2)\n",
    "        loss = 0.5 * negative_cosine_similarity(p1, z2) + 0.5 * negative_cosine_similarity(p2, z1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        loop.set_postfix(loss=f\"{np.mean(epoch_losses):.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_loss = float(np.mean(epoch_losses))\n",
    "    print(f\"Epoch {epoch+1} finished. Avg loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "    ck = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"scheduler_state\": scheduler.state_dict(),\n",
    "        \"avg_loss\": avg_loss,\n",
    "        \"manifest\": split_manifest\n",
    "    }\n",
    "    save_checkpoint(ck, latest_ckpt)\n",
    "\n",
    "\n",
    "torch.save({\"encoder_state_dict\": model.encoder.state_dict(), \"feat_dim\": model.feat_dim},\n",
    "           encoder_outpath)\n",
    "print(\"Pretraining complete. Encoder saved to\", encoder_outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 10 - Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T17:01:06.597033Z",
     "iopub.status.busy": "2025-11-27T17:01:06.596389Z",
     "iopub.status.idle": "2025-11-27T17:10:10.964330Z",
     "shell.execute_reply": "2025-11-27T17:10:10.963434Z",
     "shell.execute_reply.started": "2025-11-27T17:01:06.597007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train features: (1296, 512) to /kaggle/working/simsiam_task4/train_feats.npy\n",
      "Saved val features: (144, 512) to /kaggle/working/simsiam_task4/val_feats.npy\n",
      "Saved test features: (360, 512) to /kaggle/working/simsiam_task4/test_feats.npy\n"
     ]
    }
   ],
   "source": [
    "enc_ckpt = os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\n",
    "if not os.path.exists(enc_ckpt):\n",
    "    if 'model' in globals() and hasattr(model, \"encoder\"):\n",
    "        encoder = model.encoder\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Encoder checkpoint not found and model not in memory.\")\n",
    "else:\n",
    "    d = torch.load(enc_ckpt, map_location=DEVICE)\n",
    "    encoder = SimSiam(backbone=BACKBONE).encoder\n",
    "    encoder.load_state_dict(d[\"encoder_state_dict\"])\n",
    "encoder = encoder.to(DEVICE)\n",
    "encoder.eval()\n",
    "\n",
    "\n",
    "def extract_and_save(paths_list, labels_list, split_name):\n",
    "    ds = ManifestDataset(paths_list, labels_list, eval_transform)\n",
    "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    feats = []\n",
    "    files = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls, ps in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            h = encoder(imgs).view(imgs.size(0), -1).cpu().numpy()\n",
    "            feats.append(h)\n",
    "            files.extend(ps)\n",
    "    feats = np.vstack(feats)\n",
    "    np.save(os.path.join(OUT_DIR, f\"{split_name}_feats.npy\"), feats)\n",
    "    np.save(os.path.join(OUT_DIR, f\"{split_name}_labels.npy\"), np.array(labels_list))\n",
    "    print(f\"Saved {split_name} features: {feats.shape} to {OUT_DIR}/{split_name}_feats.npy\")\n",
    "    return feats\n",
    "\n",
    "train_feats = extract_and_save(train_paths, train_labels, \"train\")\n",
    "val_feats = extract_and_save(val_paths, val_labels, \"val\")\n",
    "test_feats = extract_and_save(test_paths, test_labels, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 11 - Linear probe + shallow heads evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T17:11:25.170271Z",
     "iopub.status.busy": "2025-11-27T17:11:25.169950Z",
     "iopub.status.idle": "2025-11-27T17:11:38.413269Z",
     "shell.execute_reply": "2025-11-27T17:11:38.412439Z",
     "shell.execute_reply.started": "2025-11-27T17:11:25.170246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: LogisticRegression\n",
      " LogisticRegression val_acc: 0.8333 test_acc: 0.8167\n",
      "Training: SVM_RBF\n",
      " SVM_RBF val_acc: 0.7917 test_acc: 0.7806\n",
      "Training: RandomForest\n",
      " RandomForest val_acc: 0.8611 test_acc: 0.8083\n",
      "Training: DecisionTree\n",
      " DecisionTree val_acc: 0.7292 test_acc: 0.6611\n",
      "Training: MLP\n",
      " MLP val_acc: 0.8472 test_acc: 0.8500\n",
      "Probe results saved to /kaggle/working/simsiam_task4/probe_results.json\n"
     ]
    }
   ],
   "source": [
    "train_feats = np.load(os.path.join(OUT_DIR, \"train_feats.npy\"))\n",
    "train_lbls = np.load(os.path.join(OUT_DIR, \"train_labels.npy\"))\n",
    "val_feats = np.load(os.path.join(OUT_DIR, \"val_feats.npy\"))\n",
    "val_lbls = np.load(os.path.join(OUT_DIR, \"val_labels.npy\"))\n",
    "test_feats = np.load(os.path.join(OUT_DIR, \"test_feats.npy\"))\n",
    "test_lbls = np.load(os.path.join(OUT_DIR, \"test_labels.npy\"))\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
    "    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(512,), max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(\"Training:\", name)\n",
    "    clf.fit(train_feats, train_lbls)\n",
    "    val_pred = clf.predict(val_feats)\n",
    "    val_acc = accuracy_score(val_lbls, val_pred)\n",
    "    test_pred = clf.predict(test_feats)\n",
    "    test_acc = accuracy_score(test_lbls, test_pred)\n",
    "    print(f\" {name} val_acc: {val_acc:.4f} test_acc: {test_acc:.4f}\")\n",
    "    results[name] = {\"val_acc\": float(val_acc), \"test_acc\": float(test_acc)}\n",
    "    joblib.dump(clf, os.path.join(OUT_DIR, f\"{name}.joblib\"))\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"probe_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Probe results saved to\", os.path.join(OUT_DIR, \"probe_results.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CELL 12 - Full fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T02:17:17.601351Z",
     "iopub.status.busy": "2025-11-27T02:17:17.601020Z",
     "iopub.status.idle": "2025-11-27T12:09:11.346078Z",
     "shell.execute_reply": "2025-11-27T12:09:11.345255Z",
     "shell.execute_reply.started": "2025-11-27T02:17:17.601329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/50: 100%|██████████| 21/21 [10:45<00:00, 30.75s/it, train_loss=0.8789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/50 - train_loss: 0.8789 val_acc: 0.6875\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/50: 100%|██████████| 21/21 [10:31<00:00, 30.05s/it, train_loss=0.5919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/50 - train_loss: 0.5919 val_acc: 0.7222\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/50: 100%|██████████| 21/21 [10:14<00:00, 29.26s/it, train_loss=0.7003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/50 - train_loss: 0.7003 val_acc: 0.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/50: 100%|██████████| 21/21 [10:24<00:00, 29.72s/it, train_loss=0.5374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/50 - train_loss: 0.5374 val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/50: 100%|██████████| 21/21 [10:24<00:00, 29.72s/it, train_loss=0.5268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/50 - train_loss: 0.5268 val_acc: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/50: 100%|██████████| 21/21 [10:42<00:00, 30.62s/it, train_loss=0.4216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/50 - train_loss: 0.4216 val_acc: 0.8542\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/50: 100%|██████████| 21/21 [10:35<00:00, 30.27s/it, train_loss=0.3410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/50 - train_loss: 0.3410 val_acc: 0.7153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/50: 100%|██████████| 21/21 [10:36<00:00, 30.31s/it, train_loss=0.3464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/50 - train_loss: 0.3464 val_acc: 0.8750\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/50: 100%|██████████| 21/21 [10:36<00:00, 30.33s/it, train_loss=0.3185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/50 - train_loss: 0.3185 val_acc: 0.8889\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.2622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/50 - train_loss: 0.2622 val_acc: 0.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 11/50: 100%|██████████| 21/21 [10:55<00:00, 31.20s/it, train_loss=0.2276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 11/50 - train_loss: 0.2276 val_acc: 0.8403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 12/50: 100%|██████████| 21/21 [10:50<00:00, 30.98s/it, train_loss=0.2587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 12/50 - train_loss: 0.2587 val_acc: 0.8958\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 13/50: 100%|██████████| 21/21 [10:53<00:00, 31.12s/it, train_loss=0.2122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 13/50 - train_loss: 0.2122 val_acc: 0.9444\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 14/50: 100%|██████████| 21/21 [10:56<00:00, 31.27s/it, train_loss=0.2195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 14/50 - train_loss: 0.2195 val_acc: 0.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 15/50: 100%|██████████| 21/21 [10:37<00:00, 30.35s/it, train_loss=0.2529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 15/50 - train_loss: 0.2529 val_acc: 0.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 16/50: 100%|██████████| 21/21 [10:32<00:00, 30.14s/it, train_loss=0.1418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 16/50 - train_loss: 0.1418 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 17/50: 100%|██████████| 21/21 [10:21<00:00, 29.59s/it, train_loss=0.1043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 17/50 - train_loss: 0.1043 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 18/50: 100%|██████████| 21/21 [10:42<00:00, 30.59s/it, train_loss=0.0951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 18/50 - train_loss: 0.0951 val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 19/50: 100%|██████████| 21/21 [10:38<00:00, 30.40s/it, train_loss=0.0772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 19/50 - train_loss: 0.0772 val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 20/50: 100%|██████████| 21/21 [10:37<00:00, 30.38s/it, train_loss=0.0750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 20/50 - train_loss: 0.0750 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 21/50: 100%|██████████| 21/21 [10:37<00:00, 30.36s/it, train_loss=0.0699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 21/50 - train_loss: 0.0699 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 22/50: 100%|██████████| 21/21 [10:29<00:00, 29.96s/it, train_loss=0.0748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 22/50 - train_loss: 0.0748 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 23/50: 100%|██████████| 21/21 [10:29<00:00, 29.96s/it, train_loss=0.0591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 23/50 - train_loss: 0.0591 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 24/50: 100%|██████████| 21/21 [10:49<00:00, 30.93s/it, train_loss=0.0852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 24/50 - train_loss: 0.0852 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 25/50: 100%|██████████| 21/21 [10:32<00:00, 30.10s/it, train_loss=0.0999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 25/50 - train_loss: 0.0999 val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 26/50: 100%|██████████| 21/21 [10:40<00:00, 30.49s/it, train_loss=0.0599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 26/50 - train_loss: 0.0599 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 27/50: 100%|██████████| 21/21 [10:29<00:00, 29.97s/it, train_loss=0.0674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 27/50 - train_loss: 0.0674 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 28/50: 100%|██████████| 21/21 [10:29<00:00, 29.98s/it, train_loss=0.0546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 28/50 - train_loss: 0.0546 val_acc: 0.9514\n",
      "Saved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 29/50: 100%|██████████| 21/21 [10:31<00:00, 30.06s/it, train_loss=0.0487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 29/50 - train_loss: 0.0487 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 30/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.0500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 30/50 - train_loss: 0.0500 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 31/50: 100%|██████████| 21/21 [10:39<00:00, 30.43s/it, train_loss=0.0388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 31/50 - train_loss: 0.0388 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 32/50: 100%|██████████| 21/21 [10:43<00:00, 30.62s/it, train_loss=0.0415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 32/50 - train_loss: 0.0415 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 33/50: 100%|██████████| 21/21 [10:45<00:00, 30.74s/it, train_loss=0.0404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 33/50 - train_loss: 0.0404 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 34/50: 100%|██████████| 21/21 [10:38<00:00, 30.39s/it, train_loss=0.0412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 34/50 - train_loss: 0.0412 val_acc: 0.9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 35/50: 100%|██████████| 21/21 [10:38<00:00, 30.39s/it, train_loss=0.0595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 35/50 - train_loss: 0.0595 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 36/50: 100%|██████████| 21/21 [10:49<00:00, 30.91s/it, train_loss=0.0339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 36/50 - train_loss: 0.0339 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 37/50: 100%|██████████| 21/21 [10:48<00:00, 30.90s/it, train_loss=0.0386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 37/50 - train_loss: 0.0386 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 38/50: 100%|██████████| 21/21 [10:33<00:00, 30.17s/it, train_loss=0.0415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 38/50 - train_loss: 0.0415 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 39/50: 100%|██████████| 21/21 [10:24<00:00, 29.73s/it, train_loss=0.0358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 39/50 - train_loss: 0.0358 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 40/50: 100%|██████████| 21/21 [10:46<00:00, 30.78s/it, train_loss=0.0500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 40/50 - train_loss: 0.0500 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 41/50: 100%|██████████| 21/21 [10:43<00:00, 30.64s/it, train_loss=0.0360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 41/50 - train_loss: 0.0360 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 42/50: 100%|██████████| 21/21 [10:36<00:00, 30.30s/it, train_loss=0.0315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 42/50 - train_loss: 0.0315 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 43/50: 100%|██████████| 21/21 [10:34<00:00, 30.20s/it, train_loss=0.0389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 43/50 - train_loss: 0.0389 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 44/50: 100%|██████████| 21/21 [10:45<00:00, 30.76s/it, train_loss=0.0408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 44/50 - train_loss: 0.0408 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 45/50: 100%|██████████| 21/21 [10:38<00:00, 30.43s/it, train_loss=0.0409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 45/50 - train_loss: 0.0409 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 46/50: 100%|██████████| 21/21 [10:36<00:00, 30.32s/it, train_loss=0.0494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 46/50 - train_loss: 0.0494 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 47/50: 100%|██████████| 21/21 [10:39<00:00, 30.43s/it, train_loss=0.0380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 47/50 - train_loss: 0.0380 val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 48/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.0347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 48/50 - train_loss: 0.0347 val_acc: 0.9514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 49/50: 100%|██████████| 21/21 [10:33<00:00, 30.18s/it, train_loss=0.0328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 49/50 - train_loss: 0.0328 val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 50/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.0322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 50/50 - train_loss: 0.0322 val_acc: 0.9375\n",
      "Fine-tune complete. Best val acc: 0.9513888888888888\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ft_num_workers = 0\n",
    "pin_memory = True if torch.cuda.is_available() else False\n",
    "resume_ckpt_path = os.path.join(OUT_DIR, \"finetune_resume.pth\")\n",
    "best_ckpt_path = os.path.join(OUT_DIR, \"finetune_best.pth\")\n",
    "save_every_epoch = True    \n",
    "if 'encoder' not in globals() or encoder is None:\n",
    "    enc_candidates = [\n",
    "        os.path.join(OUT_DIR, \"simsiam_encoder_memory.pth\"),\n",
    "        os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\n",
    "    ]\n",
    "    found = None\n",
    "    for p in enc_candidates:\n",
    "        if os.path.exists(p):\n",
    "            found = p\n",
    "            break\n",
    "    if found is None:\n",
    "        raise FileNotFoundError(\"Encoder checkpoint not found in OUT_DIR. Run pretraining or restore archive.\")\n",
    "    enc_ck = torch.load(found, map_location=\"cpu\", weights_only=False)\n",
    " \n",
    "    BACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\n",
    "    tmp_model = SimSiam(backbone=BACKBONE)\n",
    "    tmp_model.encoder.load_state_dict(enc_ck[\"encoder_state_dict\"])\n",
    "    encoder = tmp_model.encoder\n",
    "    del tmp_model\n",
    "\n",
    "\n",
    "encoder = encoder.to(DEVICE)\n",
    "\n",
    "\n",
    "class FineTuneClassifier(nn.Module):\n",
    "    def __init__(self, encoder, feat_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).view(x.size(0), -1)\n",
    "        return self.head(h)\n",
    "\n",
    "\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    dummy = torch.zeros(1, 3, RESOLUTION, RESOLUTION).to(DEVICE)\n",
    "    try:\n",
    "        out = encoder(dummy).view(1, -1)\n",
    "        feat_dim = out.shape[1]\n",
    "    except Exception:\n",
    "        feat_dim = 512 if BACKBONE == \"resnet18\" else 2048\n",
    "\n",
    "num_classes = len(classes)\n",
    "ft_model = FineTuneClassifier(encoder, feat_dim, num_classes).to(DEVICE)\n",
    "\n",
    "\n",
    "ft_train_transform = transforms.Compose([\n",
    "    transforms.Resize(int(RESOLUTION*1.1)),\n",
    "    transforms.CenterCrop(RESOLUTION),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "ft_train_ds = ManifestDataset(train_paths, train_labels, ft_train_transform)\n",
    "ft_val_ds = ManifestDataset(val_paths, val_labels, eval_transform)\n",
    "\n",
    "ft_train_loader = DataLoader(ft_train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                             num_workers=ft_num_workers, pin_memory=pin_memory)\n",
    "ft_val_loader   = DataLoader(ft_val_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             num_workers=ft_num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "ft_optimizer = optim.SGD(ft_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "ft_scheduler = optim.lr_scheduler.StepLR(ft_optimizer, step_size=15, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "start_epoch = 0\n",
    "best_val_acc = 0.0\n",
    "if os.path.exists(resume_ckpt_path):\n",
    "    try:\n",
    "        ck = torch.load(resume_ckpt_path, map_location=DEVICE, weights_only=False)\n",
    "        ft_model.load_state_dict(ck[\"model_state\"])\n",
    "        ft_optimizer.load_state_dict(ck[\"optimizer_state\"])\n",
    "        if \"scheduler_state\" in ck:\n",
    "            try:\n",
    "                ft_scheduler.load_state_dict(ck[\"scheduler_state\"])\n",
    "            except Exception:\n",
    "                pass\n",
    "        start_epoch = ck.get(\"epoch\", 0) + 1\n",
    "        best_val_acc = ck.get(\"val_acc\", 0.0)\n",
    "        print(f\"Resumed fine-tune from resume checkpoint at epoch {start_epoch} (best val {best_val_acc:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not resume from resume checkpoint:\", e)\n",
    "\n",
    "\n",
    "elif os.path.exists(best_ckpt_path):\n",
    "    try:\n",
    "        ck = torch.load(best_ckpt_path, map_location=DEVICE, weights_only=False)\n",
    "        ft_model.load_state_dict(ck[\"model_state\"])\n",
    "        best_val_acc = ck.get(\"val_acc\", 0.0)\n",
    "        print(\"Initialized fine-tune from best checkpoint (val_acc={:.4f})\".format(best_val_acc))\n",
    "    except Exception as e:\n",
    "        print(\"Could not load best checkpoint as init:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    for epoch in range(start_epoch, FINETUNE_EPOCHS):\n",
    "        ft_model.train()\n",
    "        losses = []\n",
    "        loop = tqdm(ft_train_loader, desc=f\"Fine-tune Epoch {epoch+1}/{FINETUNE_EPOCHS}\")\n",
    "        for imgs, labels_batch, _ in loop:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=pin_memory)\n",
    "            labels_batch = labels_batch.to(DEVICE, non_blocking=pin_memory)\n",
    "            logits = ft_model(imgs)\n",
    "            loss = criterion(logits, labels_batch)\n",
    "            ft_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            ft_optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            loop.set_postfix(train_loss=f\"{np.mean(losses):.4f}\")\n",
    "\n",
    "        ft_scheduler.step()\n",
    "\n",
    "\n",
    "        ft_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels_batch, _ in ft_val_loader:\n",
    "                imgs = imgs.to(DEVICE, non_blocking=pin_memory)\n",
    "                logits = ft_model(imgs)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels_batch.numpy())\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        print(f\"Fine-tune Epoch {epoch+1}/{FINETUNE_EPOCHS} - train_loss: {np.mean(losses):.4f} val_acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": ft_model.state_dict(),\n",
    "                \"optimizer_state\": ft_optimizer.state_dict(),\n",
    "                \"val_acc\": val_acc\n",
    "            }, best_ckpt_path)\n",
    "            print(\"Saved best fine-tune checkpoint:\", best_ckpt_path)\n",
    "\n",
    "\n",
    "        if save_every_epoch:\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": ft_model.state_dict(),\n",
    "                \"optimizer_state\": ft_optimizer.state_dict(),\n",
    "                \"scheduler_state\": ft_scheduler.state_dict(),\n",
    "                \"val_acc\": val_acc\n",
    "            }, resume_ckpt_path)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "\n",
    "    print(\"KeyboardInterrupt caught — saving resume checkpoint...\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": ft_model.state_dict(),\n",
    "        \"optimizer_state\": ft_optimizer.state_dict(),\n",
    "        \"scheduler_state\": ft_scheduler.state_dict(),\n",
    "        \"val_acc\": best_val_acc\n",
    "    }, resume_ckpt_path)\n",
    "    print(\"Saved resume checkpoint to\", resume_ckpt_path)\n",
    "    raise\n",
    "\n",
    "print(\"Fine-tune complete. Best val acc:\", best_val_acc)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8515242,
     "sourceId": 13416578,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8828035,
     "sourceId": 13857847,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8854929,
     "sourceId": 13898650,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
